{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOwI+jxZZR8+PzBQ3crRxC2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyounghe0724/StartPytorch/blob/main/Cross_Vaildation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHbtJ17DW4cy",
        "outputId": "95cf459f-6989-4b54-a266-3e2b96298a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nvduHyLaabg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/gdrive/My Drive/GoogleColab/deeplearningbrov2/pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSdPA6ljaaIa",
        "outputId": "69a787f3-deeb-43b9-d7b9-71a59251f3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/GoogleColab/deeplearningbrov2/pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "wOXlUUKFaakH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kMxRztRgaavu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C7GzhgMPaRDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split # 전체 데이터를 학습 데이터와 평가 데이터로 나눈다.\\\n",
        "import torch\n",
        "from torch import nn, optim # torch 내의 세부적인 기능을 불러온다. (신경망 기술, 손실함수, 최적화 방법 등)\n",
        "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n",
        "import torch.nn.functional as F # torch 내의 세부적인 기능을 불러온다. (신경망 기술 등)\n",
        "\n",
        "# Cross Validation\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Plot\n",
        "import matplotlib.pyplot as plt # 시각화 도구"
      ],
      "metadata": {
        "id": "J7RoMC3gadPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('./data/reg.csv', index_col=[0])\n",
        "# 데이터를 넘파이 배열로 만들기\n",
        "X = df.drop(\"Price\", axis=1).to_numpy() # target 값 price를 제외하고 넘파이 배열로 만듬\n",
        "Y = df[\"Price\"].to_numpy().reshape((-1,1)) # (n,) 1차원을 (n,1) 2차원으로 만들어준다.\n",
        "# -1은 행의 갯수를 자동으로 계산, 1은 [[a], [b]..]처럼 col값이 1로 설정인다.\n"
      ],
      "metadata": {
        "id": "x0yrCeytarkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서 데이터로 변환하는 클래스\n",
        "class TensorData(Dataset):\n",
        "\n",
        "  def __init__(self, x_data, y_data):\n",
        "    self.x_data = torch.FloatTensor(x_data)\n",
        "    self.y_data = torch.FloatTensor(y_data)\n",
        "    self.len = self.y_data.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.x_data[index], self.y_data[index]\n",
        "\n",
        "  def __len__(self,):\n",
        "    return self.len\n",
        "\n"
      ],
      "metadata": {
        "id": "TrhbiSOVbrB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test  = train_test_split(X,Y, test_size=0.7)\n",
        "trainset = TensorData(X_train, Y_train)\n",
        "\n",
        "testset = TensorData(X_test, Y_test)\n",
        "testloader = DataLoader(testset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "WCcQ1YkOdaQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Regressor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(13,50,bias = True)\n",
        "    self.fc2 = nn.Linear(50,30,bias = True)\n",
        "    self.fc3 = nn.Linear(30,1,bias = True)\n",
        "    self.dropout = nn.Dropout(0.2) # 연산이 될 때 마다 2e-1 비율로 랜덤하게 노드를 없앤다.\n",
        "    # overfitting 방지\n",
        "    # 네트워크의 일부만을 사용, 서로 다른 하위모델들이 동시에 학습되는 효과\n",
        "\n",
        "  def forward(self, x):\n",
        "    x= F.relu(self.fc1(x))\n",
        "    x = self.dropout(F.relu(self.fc2(x))) # Hidden layer에만 사용 출력층에서 사용해서는 안된다\n",
        "    x= F.relu(self.fc3(x))\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "rFJE2fvhdtsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3, shuffle=True)\n"
      ],
      "metadata": {
        "id": "OpaeV6bCgOdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "xbvh63-xgVdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(dataloader):\n",
        "  with torch.no_grad():\n",
        "    square_sum = 0\n",
        "    num_instances = 0\n",
        "    model.eval()\n",
        "    for data in dataloader:\n",
        "      inputs, targets = data\n",
        "      outputs = model(inputs)\n",
        "      square_sum += torch.sum((outputs - targets)**2).item()\n",
        "      num_instances += len(targets)\n",
        "  model.train()\n",
        "  return np.sqrt(square_sum/num_instances)"
      ],
      "metadata": {
        "id": "_9aBCSgCgcw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 평가 모델들에 대해서 CV 진행\n",
        "vaildation_loss = []\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(trainset)):\n",
        "  train_subsampler = SubsetRandomSampler(train_idx)\n",
        "  val_subsmapler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "  trainloader = DataLoader(trainset, batch_size=32, sampler=train_subsampler)\n",
        "  valloader = DataLoader(trainset, batch_size=32, sampler=val_subsmapler)\n",
        "\n",
        "  model = Regressor()\n",
        "  optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=3e-3)\n",
        "\n",
        "  for epoch in range(200):\n",
        "\n",
        "    for data in trainloader:\n",
        "\n",
        "      inputs, values = data # X, Y\n",
        "      optimizer.zero_grad() # 최적화 초기화\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, values)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "  train_rmse = rmse(trainloader)\n",
        "  val_rmse = rmse(valloader)\n",
        "  print(\"f-fold\", fold, \" Train Loss : %.4f, vaildation Loss: %.4f\" %(train_rmse, val_rmse))\n",
        "  vaildation_loss.append(val_rmse)\n",
        "\n",
        "vaildation_loss = np.array(vaildation_loss)\n",
        "mean = np.mean(vaildation_loss)\n",
        "std = np.std(vaildation_loss)\n",
        "print(\"Validation Score: %.4f, ± %.4f\" %(mean, std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYDCh0QQg3ed",
        "outputId": "1472c98a-b8b3-4c6e-cbb5-feaa6b52a87a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f-fold 0  Train Loss : 0.1130, vaildation Loss: 0.1115\n",
            "f-fold 1  Train Loss : 0.0928, vaildation Loss: 0.1534\n",
            "f-fold 2  Train Loss : 0.1196, vaildation Loss: 0.1232\n",
            "Validation Score: 0.1294, ± 0.0177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CV를 통해 best model를 정했다면 평가를 진행한다.\n",
        "# 전체 학습 데이터를 이용한 DataLoader 정의\n",
        "trainloader = DataLoader(trainset, batch_size=32)\n",
        "\n",
        "# 모델\n",
        "model = Regressor()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-2, weight_decay=3e-3)\n",
        "\n",
        "for epoch in range(200): # 200번 학습을 진행한다.\n",
        "\n",
        "    for data in trainloader: # 무작위로 섞인 32개 데이터가 있는 배치가 하나 씩 들어온다.\n",
        "\n",
        "        inputs, values = data # data에는 X, Y가 들어있다.\n",
        "\n",
        "        optimizer.zero_grad() # 최적화 초기화\n",
        "\n",
        "        outputs = model(inputs) # 모델에 입력값 대입 후 예측값 산출\n",
        "        loss = criterion(outputs, values) # 손실 함수 계산\n",
        "        loss.backward() # 손실 함수 기준으로 역전파 설정\n",
        "        optimizer.step() # 역전파를 진행하고 가중치 업데이트"
      ],
      "metadata": {
        "id": "w0YW6aFdj4BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_rmse = rmse(trainloader) # 학습 데이터의 RMSE\n",
        "test_rmse = rmse(testloader) # 시험 데이터의 RMSE\n",
        "print(\" Train Loss: %.4f, Test Loss: %.4f\" %(train_rmse, test_rmse))"
      ],
      "metadata": {
        "id": "_X9FOHGqmw1Z",
        "outputId": "367435a8-264b-40c4-b7da-a2d6959ac325",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Train Loss: 0.1034, Test Loss: 0.1127\n"
          ]
        }
      ]
    }
  ]
}